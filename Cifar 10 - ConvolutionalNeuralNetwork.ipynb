{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from urllib.request import urlretrieve\n",
        "from os.path import isfile, isdir\n",
        "from tqdm import tqdm\n",
        "import problem_unittests as tests\n",
        "import tarfile\n",
        "\n",
        "cifar10_dataset_folder_path = 'cifar-10-batches-py'\n",
        "\n",
        "class DLProgress(tqdm):\n",
        "    last_block = 0\n",
        "\n",
        "    def hook(self, block_num=1, block_size=1, total_size=None):\n",
        "        self.total = total_size\n",
        "        self.update((block_num - self.last_block) * block_size)\n",
        "        self.last_block = block_num\n",
        "\n",
        "if not isfile('cifar-10-python.tar.gz'):\n",
        "    with DLProgress(unit='B', unit_scale=True, miniters=1, desc='CIFAR-10 Dataset') as pbar:\n",
        "        urlretrieve(\n",
        "            'https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz',\n",
        "            'cifar-10-python.tar.gz',\n",
        "            pbar.hook)\n",
        "\n",
        "if not isdir(cifar10_dataset_folder_path):\n",
        "    with tarfile.open('cifar-10-python.tar.gz') as tar:\n",
        "        tar.extractall()\n",
        "        tar.close()\n",
        "\n",
        "\n",
        "tests.test_folder_path(cifar10_dataset_folder_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9kuBtqF8UFHO",
        "outputId": "38f56402-4a20-40c0-dcf3-87a8b91d7827"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All files found!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "%config InlineBackend.figure_format = 'retina'\n",
        "\n",
        "import helper\n",
        "import numpy as np\n",
        "\n",
        "# Explore the dataset\n",
        "batch_id = 2\n",
        "sample_id = 4\n",
        "helper.display_stats(cifar10_dataset_folder_path, batch_id, sample_id)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 433
        },
        "id": "r6YL-BiyUH_X",
        "outputId": "94cf1771-d112-4698-907c-e33a98c5310c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Stats of batch 2:\n",
            "Samples: 10000\n",
            "Label Counts: {0: 984, 1: 1007, 2: 1010, 3: 995, 4: 1010, 5: 988, 6: 1008, 7: 1026, 8: 987, 9: 985}\n",
            "First 20 Labels: [1, 6, 6, 8, 8, 3, 4, 6, 0, 6, 0, 3, 6, 6, 5, 4, 8, 3, 2, 6]\n",
            "\n",
            "Example of Image 4:\n",
            "Image - Min Value: 0 Max Value: 255\n",
            "Image - Shape: (32, 32, 3)\n",
            "Label - Label Id: 8 Name: ship\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "image/png": {
              "width": 231,
              "height": 231
            },
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def normalize(x):\n",
        "    \"\"\"\n",
        "    Normalize a list of sample image data in the range of 0 to 1\n",
        "    : x: List of image data.  The image shape is (32, 32, 3)\n",
        "    : return: Numpy array of normalize data\n",
        "    \"\"\"\n",
        "    # TODO: Implement Function\n",
        "    return x / 255 # x - np.min(x) / (np.max(x) - np.min(x))\n",
        "\n",
        "tests.test_normalize(normalize)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G1yXdLnxUKsp",
        "outputId": "0b1bf245-7fbf-4ece-d97c-7fc601d3c0c1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tests Passed\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def one_hot_encode(x):\n",
        "    \"\"\"\n",
        "    One hot encode a list of sample labels. Return a one-hot encoded vector for each label.\n",
        "    : x: List of sample Labels\n",
        "    : return: Numpy array of one-hot encoded labels\n",
        "    \"\"\"\n",
        "    # TODO: Implement Function\n",
        "    z = np.zeros((len(x), 10))\n",
        "    z[list(np.indices((len(x),))) + [x]] = 1\n",
        "    return z\n",
        "\n",
        "tests.test_one_hot_encode(one_hot_encode)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WhrwoqBLUNbd",
        "outputId": "c1253bf6-338f-448a-eb7d-e929220b718d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tests Passed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:9: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
            "  if __name__ == '__main__':\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocess Training, Validation, and Testing Data\n",
        "helper.preprocess_and_save_data(cifar10_dataset_folder_path, normalize, one_hot_encode)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lYKv6GURUPsO",
        "outputId": "c77e5137-355a-4c1a-a632-03005366b17b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:9: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
            "  if __name__ == '__main__':\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "import problem_unittests as tests\n",
        "import helper\n",
        "\n",
        "# Load the Preprocessed Validation data\n",
        "valid_features, valid_labels = pickle.load(open('preprocess_validation.p', mode='rb'))"
      ],
      "metadata": {
        "id": "GMFW5bAfUXZn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow.compat.v1 as tf\n",
        "tf.disable_v2_behavior() \n",
        "\n",
        "def neural_net_image_input(image_shape):\n",
        "    \"\"\"\n",
        "    Return a Tensor for a batch of image input\n",
        "    : image_shape: Shape of the images\n",
        "    : return: Tensor for image input.\n",
        "    \"\"\"\n",
        "    # TODO: Implement Function\n",
        "    return tf.placeholder(tf.float32, shape=(None,)+image_shape, name='x')\n",
        "\n",
        "\n",
        "def neural_net_label_input(n_classes):\n",
        "    \"\"\"\n",
        "    Return a Tensor for a batch of label input\n",
        "    : n_classes: Number of classes\n",
        "    : return: Tensor for label input.\n",
        "    \"\"\"\n",
        "    # TODO: Implement Function\n",
        "    return tf.placeholder(tf.float32, shape=(None, n_classes), name='y')\n",
        "\n",
        "\n",
        "def neural_net_keep_prob_input():\n",
        "    \"\"\"\n",
        "    Return a Tensor for keep probability\n",
        "    : return: Tensor for keep probability.\n",
        "    \"\"\"\n",
        "    # TODO: Implement Function\n",
        "    return tf.placeholder(tf.float32, name='keep_prob')\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
        "\"\"\"\n",
        "tf.reset_default_graph()\n",
        "tests.test_nn_image_inputs(neural_net_image_input)\n",
        "tests.test_nn_label_inputs(neural_net_label_input)\n",
        "tests.test_nn_keep_prob_inputs(neural_net_keep_prob_input)\n",
        "\n",
        "def conv2d_maxpool(x_tensor, conv_num_outputs, conv_ksize, conv_strides, pool_ksize, pool_strides):\n",
        "    \"\"\"\n",
        "    Apply convolution then max pooling to x_tensor\n",
        "    :param x_tensor: TensorFlow Tensor\n",
        "    :param conv_num_outputs: Number of outputs for the convolutional layer\n",
        "    :param conv_ksize: kernal size 2-D Tuple for the convolutional layer\n",
        "    :param conv_strides: Stride 2-D Tuple for convolution\n",
        "    :param pool_ksize: kernal size 2-D Tuple for pool\n",
        "    :param pool_strides: Stride 2-D Tuple for pool\n",
        "    : return: A tensor that represents convolution and max pooling of x_tensor\n",
        "    \"\"\"\n",
        "    # TODO: Implement Function\n",
        "    \n",
        "    # Weight and bias\n",
        "    weight = tf.Variable(tf.truncated_normal([*conv_ksize, x_tensor.shape.as_list()[3], conv_num_outputs],stddev=5e-2))\n",
        "    bias = tf.Variable(tf.zeros(conv_num_outputs))\n",
        "    \n",
        "    # Apply Convolution\n",
        "    conv_layer = tf.nn.conv2d(x_tensor,\n",
        "                              weight,\n",
        "                              strides=[1, *conv_strides, 1],\n",
        "                              padding='SAME')\n",
        "    # Add bias\n",
        "    conv_layer = tf.nn.bias_add(conv_layer, bias)\n",
        "    # Apply activation function\n",
        "    conv_layer = tf.nn.relu(conv_layer)\n",
        "    \n",
        "    # Apply Max Pooling\n",
        "    conv_layer = tf.nn.max_pool(conv_layer,\n",
        "                                ksize=[1, *pool_ksize, 1],\n",
        "                                strides=[1, *pool_strides, 1],\n",
        "                                padding='SAME')\n",
        "    \n",
        "    return conv_layer\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
        "\"\"\"\n",
        "tests.test_con_pool(conv2d_maxpool)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "id": "KXa3no2mUZva",
        "outputId": "b23d941a-e460-4a1c-c267-42588478aaed"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image Input Tests Passed.\n",
            "Label Input Tests Passed.\n",
            "Keep Prob Tests Passed.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-30-c03aceb85a9b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[0mDON\u001b[0m\u001b[0;31m'\u001b[0m\u001b[0mT\u001b[0m \u001b[0mMODIFY\u001b[0m \u001b[0mANYTHING\u001b[0m \u001b[0mIN\u001b[0m \u001b[0mTHIS\u001b[0m \u001b[0mCELL\u001b[0m \u001b[0mTHAT\u001b[0m \u001b[0mIS\u001b[0m \u001b[0mBELOW\u001b[0m \u001b[0mTHIS\u001b[0m \u001b[0mLINE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m \"\"\"\n\u001b[0;32m---> 80\u001b[0;31m \u001b[0mtests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_con_pool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconv2d_maxpool\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/content/problem_unittests.py\u001b[0m in \u001b[0;36mtest_con_pool\u001b[0;34m(conv2d_maxpool)\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Keep Prob Tests Passed.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    127\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtest_con_pool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconv2d_maxpool\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: module 'tensorflow' has no attribute 'placeholder'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def flatten(x_tensor):\n",
        "    \"\"\"\n",
        "    Flatten x_tensor to (Batch Size, Flattened Image Size)\n",
        "    : x_tensor: A tensor of size (Batch Size, ...), where ... are the image dimensions.\n",
        "    : return: A tensor of size (Batch Size, Flattened Image Size).\n",
        "    \"\"\"\n",
        "    # TODO: Implement Function\n",
        "    return tf.contrib.layers.flatten(x_tensor)\n",
        "\n",
        "tests.test_flatten(flatten)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        },
        "id": "6HI9c5THWvsY",
        "outputId": "1e79d12d-2e1b-4d1b-d4ae-b9f6cb0dbaaf"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-25-cc5b691a1dd9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0mDON\u001b[0m\u001b[0;31m'\u001b[0m\u001b[0mT\u001b[0m \u001b[0mMODIFY\u001b[0m \u001b[0mANYTHING\u001b[0m \u001b[0mIN\u001b[0m \u001b[0mTHIS\u001b[0m \u001b[0mCELL\u001b[0m \u001b[0mTHAT\u001b[0m \u001b[0mIS\u001b[0m \u001b[0mBELOW\u001b[0m \u001b[0mTHIS\u001b[0m \u001b[0mLINE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \"\"\"\n\u001b[0;32m---> 40\u001b[0;31m \u001b[0mtests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_con_pool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconv2d_maxpool\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/content/problem_unittests.py\u001b[0m in \u001b[0;36mtest_con_pool\u001b[0;34m(conv2d_maxpool)\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtest_con_pool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconv2d_maxpool\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m     \u001b[0mtest_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplaceholder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    127\u001b[0m     \u001b[0mtest_num_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m     \u001b[0mtest_con_k\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: module 'tensorflow' has no attribute 'placeholder'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def fully_conn(x_tensor, num_outputs):\n",
        "    \"\"\"\n",
        "    Apply a fully connected layer to x_tensor using weight and bias\n",
        "    : x_tensor: A 2-D tensor where the first dimension is batch size.\n",
        "    : num_outputs: The number of output that the new tensor should be.\n",
        "    : return: A 2-D tensor where the second dimension is num_outputs.\n",
        "    \"\"\"\n",
        "    # TODO: Implement Function\n",
        "    return tf.layers.dense(x_tensor, num_outputs, activation=tf.nn.relu)\n",
        "\n",
        "tests.test_fully_conn(fully_conn)"
      ],
      "metadata": {
        "id": "K1FIZWaIX46y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def output(x_tensor, num_outputs):\n",
        "    \"\"\"\n",
        "    Apply a output layer to x_tensor using weight and bias\n",
        "    : x_tensor: A 2-D tensor where the first dimension is batch size.\n",
        "    : num_outputs: The number of output that the new tensor should be.\n",
        "    : return: A 2-D tensor where the second dimension is num_outputs.\n",
        "    \"\"\"\n",
        "    # TODO: Implement Function\n",
        "    return tf.layers.dense(x_tensor, num_outputs)\n",
        "\n",
        "tests.test_output(output)"
      ],
      "metadata": {
        "id": "Ley9mRtJX6PH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def conv_net(x, keep_prob):\n",
        "    \"\"\"\n",
        "    Create a convolutional neural network model\n",
        "    : x: Placeholder tensor that holds image data.\n",
        "    : keep_prob: Placeholder tensor that hold dropout keep probability.\n",
        "    : return: Tensor that represents logits\n",
        "    \"\"\"\n",
        "    # TODO: Apply 1, 2, or 3 Convolution and Max Pool layers\n",
        "    #    Play around with different number of outputs, kernel size and stride\n",
        "    # Function Definition from Above:\n",
        "    #    conv2d_maxpool(x_tensor, conv_num_outputs, conv_ksize, conv_strides, pool_ksize, pool_strides)\n",
        "    x = conv2d_maxpool(x, 64, (5, 5), (1, 1), (3, 3), (2, 2)) # 14x14x64\n",
        "    x = tf.layers.dropout(x, rate=keep_prob)\n",
        "    x = conv2d_maxpool(x, 64, (5, 5), (1, 1), (3, 3), (2, 2)) # 7x7x64\n",
        "    x = tf.layers.dropout(x, rate=keep_prob)\n",
        "    \n",
        "\n",
        "    # TODO: Apply a Flatten Layer\n",
        "    # Function Definition from Above:\n",
        "    #   flatten(x_tensor)\n",
        "    x = flatten(x)\n",
        "    \n",
        "\n",
        "    # TODO: Apply 1, 2, or 3 Fully Connected Layers\n",
        "    #    Play around with different number of outputs\n",
        "    # Function Definition from Above:\n",
        "    #   fully_conn(x_tensor, num_outputs)\n",
        "    x = fully_conn(x, 384)\n",
        "    x = fully_conn(x, 192)\n",
        "    \n",
        "    \n",
        "    # TODO: Apply an Output Layer\n",
        "    #    Set this to the number of classes\n",
        "    # Function Definition from Above:\n",
        "    #   output(x_tensor, num_outputs)\n",
        "    x = output(x, 10)\n",
        "    \n",
        "    \n",
        "    # TODO: return output\n",
        "    return x\n",
        "\n",
        "# Remove previous weights, bias, inputs, etc..\n",
        "tf.reset_default_graph()\n",
        "\n",
        "# Inputs\n",
        "x = neural_net_image_input((32, 32, 3))\n",
        "y = neural_net_label_input(10)\n",
        "keep_prob = neural_net_keep_prob_input()\n",
        "\n",
        "# Model\n",
        "logits = conv_net(x, keep_prob)\n",
        "\n",
        "# Name logits Tensor, so that is can be loaded from disk after training\n",
        "logits = tf.identity(logits, name='logits')\n",
        "\n",
        "# Loss and Optimizer\n",
        "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=y))\n",
        "optimizer = tf.train.AdamOptimizer().minimize(cost)\n",
        "\n",
        "# Accuracy\n",
        "correct_pred = tf.equal(tf.argmax(logits, 1), tf.argmax(y, 1))\n",
        "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32), name='accuracy')\n",
        "\n",
        "tests.test_conv_net(conv_net)"
      ],
      "metadata": {
        "id": "wn3BWwQ7X8vv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_neural_network(session, optimizer, keep_probability, feature_batch, label_batch):\n",
        "    \"\"\"\n",
        "    Optimize the session on a batch of images and labels\n",
        "    : session: Current TensorFlow session\n",
        "    : optimizer: TensorFlow optimizer function\n",
        "    : keep_probability: keep probability\n",
        "    : feature_batch: Batch of Numpy image data\n",
        "    : label_batch: Batch of Numpy label data\n",
        "    \"\"\"\n",
        "    # TODO: Implement Function\n",
        "    session.run(optimizer, feed_dict={\n",
        "                x: feature_batch,\n",
        "                y: label_batch,\n",
        "                keep_prob: keep_probability})\n",
        "\n",
        "tests.test_train_nn(train_neural_network)"
      ],
      "metadata": {
        "id": "E2zaBX4lYBcF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def print_stats(session, feature_batch, label_batch, cost, accuracy):\n",
        "    \"\"\"\n",
        "    Print information about loss and validation accuracy\n",
        "    : session: Current TensorFlow session\n",
        "    : feature_batch: Batch of Numpy image data\n",
        "    : label_batch: Batch of Numpy label data\n",
        "    : cost: TensorFlow cost function\n",
        "    : accuracy: TensorFlow accuracy function\n",
        "    \"\"\"\n",
        "    # TODO: Implement Function\n",
        "    loss = sess.run(cost, feed_dict={\n",
        "        x: feature_batch,\n",
        "        y: label_batch,\n",
        "        keep_prob: 1.})\n",
        "    valid_acc = sess.run(accuracy, feed_dict={\n",
        "        x: valid_features,\n",
        "        y: valid_labels,\n",
        "        keep_prob: 1.})\n",
        "\n",
        "    print('Loss: {:>10.4f} Validation Accuracy: {:.6f}'.format(\n",
        "        loss,\n",
        "        valid_acc))"
      ],
      "metadata": {
        "id": "Ki49RQo6YEGu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: Tune Parameters\n",
        "epochs = 100\n",
        "batch_size = 256\n",
        "keep_probability = 0.75"
      ],
      "metadata": {
        "id": "ZFyQFS7gYFqS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Checking the Training on a Single Batch...')\n",
        "with tf.Session() as sess:\n",
        "    # Initializing the variables\n",
        "    sess.run(tf.global_variables_initializer())\n",
        "    \n",
        "    # Training cycle\n",
        "    for epoch in range(epochs):\n",
        "        batch_i = 1\n",
        "        for batch_features, batch_labels in helper.load_preprocess_training_batch(batch_i, batch_size):\n",
        "            train_neural_network(sess, optimizer, keep_probability, batch_features, batch_labels)\n",
        "        print('Epoch {:>2}, CIFAR-10 Batch {}:  '.format(epoch + 1, batch_i), end='')\n",
        "        print_stats(sess, batch_features, batch_labels, cost, accuracy)"
      ],
      "metadata": {
        "id": "gwnl9ofkYH_p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "DON'T MODIFY ANYTHING IN THIS CELL\n",
        "\"\"\"\n",
        "save_model_path = './image_classification'\n",
        "\n",
        "print('Training...')\n",
        "with tf.Session() as sess:\n",
        "    # Initializing the variables\n",
        "    sess.run(tf.global_variables_initializer())\n",
        "    \n",
        "    # Training cycle\n",
        "    for epoch in range(epochs):\n",
        "        # Loop over all batches\n",
        "        n_batches = 5\n",
        "        for batch_i in range(1, n_batches + 1):\n",
        "            for batch_features, batch_labels in helper.load_preprocess_training_batch(batch_i, batch_size):\n",
        "                train_neural_network(sess, optimizer, keep_probability, batch_features, batch_labels)\n",
        "            print('Epoch {:>2}, CIFAR-10 Batch {}:  '.format(epoch + 1, batch_i), end='')\n",
        "            print_stats(sess, batch_features, batch_labels, cost, accuracy)\n",
        "            \n",
        "    # Save Model\n",
        "    saver = tf.train.Saver()\n",
        "    save_path = saver.save(sess, save_model_path)"
      ],
      "metadata": {
        "id": "LfK1j5aMYMOq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "%config InlineBackend.figure_format = 'retina'\n",
        "\n",
        "import tensorflow as tf\n",
        "import pickle\n",
        "import helper\n",
        "import random\n",
        "\n",
        "# Set batch size if not already set\n",
        "try:\n",
        "    if batch_size:\n",
        "        pass\n",
        "except NameError:\n",
        "    batch_size = 64\n",
        "\n",
        "save_model_path = './image_classification'\n",
        "n_samples = 4\n",
        "top_n_predictions = 3\n",
        "\n",
        "def test_model():\n",
        "    \"\"\"\n",
        "    Test the saved model against the test dataset\n",
        "    \"\"\"\n",
        "\n",
        "    test_features, test_labels = pickle.load(open('preprocess_test.p', mode='rb'))\n",
        "    loaded_graph = tf.Graph()\n",
        "\n",
        "    with tf.Session(graph=loaded_graph) as sess:\n",
        "        # Load model\n",
        "        loader = tf.train.import_meta_graph(save_model_path + '.meta')\n",
        "        loader.restore(sess, save_model_path)\n",
        "\n",
        "        # Get Tensors from loaded model\n",
        "        loaded_x = loaded_graph.get_tensor_by_name('x:0')\n",
        "        loaded_y = loaded_graph.get_tensor_by_name('y:0')\n",
        "        loaded_keep_prob = loaded_graph.get_tensor_by_name('keep_prob:0')\n",
        "        loaded_logits = loaded_graph.get_tensor_by_name('logits:0')\n",
        "        loaded_acc = loaded_graph.get_tensor_by_name('accuracy:0')\n",
        "        \n",
        "        # Get accuracy in batches for memory limitations\n",
        "        test_batch_acc_total = 0\n",
        "        test_batch_count = 0\n",
        "        \n",
        "        for test_feature_batch, test_label_batch in helper.batch_features_labels(test_features, test_labels, batch_size):\n",
        "            test_batch_acc_total += sess.run(\n",
        "                loaded_acc,\n",
        "                feed_dict={loaded_x: test_feature_batch, loaded_y: test_label_batch, loaded_keep_prob: 1.0})\n",
        "            test_batch_count += 1\n",
        "\n",
        "        print('Testing Accuracy: {}\\n'.format(test_batch_acc_total/test_batch_count))\n",
        "\n",
        "        # Print Random Samples\n",
        "        random_test_features, random_test_labels = tuple(zip(*random.sample(list(zip(test_features, test_labels)), n_samples)))\n",
        "        random_test_predictions = sess.run(\n",
        "            tf.nn.top_k(tf.nn.softmax(loaded_logits), top_n_predictions),\n",
        "            feed_dict={loaded_x: random_test_features, loaded_y: random_test_labels, loaded_keep_prob: 1.0})\n",
        "        helper.display_image_predictions(random_test_features, random_test_labels, random_test_predictions)\n",
        "\n",
        "\n",
        "test_model()"
      ],
      "metadata": {
        "id": "t0wBpz4cYOUs"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}